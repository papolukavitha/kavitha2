# Import necessary libraries
import nltk
from nltk.corpus import movie_reviews
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Download the IMDB movie reviews dataset from nltk
nltk.download('movie_reviews')

# Load the dataset
documents = [(list(movie_reviews.words(fileid)), category)
             for category in movie_reviews.categories()
             for fileid in movie_reviews.fileids(category)]

# Shuffle the documents to create a balanced dataset
import random
random.shuffle(documents)

# Separate the features (words) and labels (positive/negative)
all_words = [word.lower() for word in movie_reviews.words()]
all_words = nltk.FreqDist(all_words)
word_features = list(all_words.keys())[:3000]  # Use the 3000 most common words as features

# Define a function to extract features from a document
def document_features(document):
    document_words = set(document)
    features = {}
    for word in word_features:
        features[word] = (word in document_words)
    return features

# Extract features for each document
featuresets = [(document_features(d), c) for (d, c) in documents]

# Split the data into training and testing sets
train_set, test_set = train_test_split(featuresets, test_size=0.2, random_state=42)

# Train a Naive Bayes classifier
classifier = nltk.NaiveBayesClassifier.train(train_set)

# Evaluate the classifier
y_true = [c for (d, c) in test_set]
y_pred = [classifier.classify(d) for (d, c) in test_set]

print(f"Accuracy: {accuracy_score(y_true, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_true, y_pred)}")
print(f"Classification Report:\n{classification_report(y_true, y_pred)}")
 
